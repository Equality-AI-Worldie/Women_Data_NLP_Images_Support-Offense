# Women Datasets ~ Labels to train NLP, NLU, Image Recognition AI with Support, Defense, Offense

Texts & photos labeled of Support and Offense of Women for creating Equality AI, Natural Language Understanding, and image recognition protections for Women on social platforms. Done to accurately label defense of Women as "Support" and offense and defense against as "Offense." 

Shows labels: support_gen, defense_gen, offense_gen, support_women, defense_women, defense_against_women

Previously data is not obtained about women or the abuse labels online did not classify about women accurately. E.g., Women's Defenders and Supporters were being labeled by NLP and by Sentiment as 'offenders' from open-source datasets.

This is a sample, worked on by an intern from the University of Chicago for Worldie - Social Media for Good.
For your purposes, you will need to edit. Further, this has errors as well. 
- Collect the Data
- Label the Data
- Train from NLP packages on the internet
- Use an NLU tester page to see the result (attached example)

Important:
- Machines look at patterns of words, so the more data is trained, the more patterns it will recognize
- See the perspective from the female viewpoint and well-being
- Look at context (previous texts, texts afterwards, images, situation)
- Look at symbolism
